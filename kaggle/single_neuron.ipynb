{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Deep Learning?\n",
    "\n",
    "Some of the most impressive advances in artificial intelligence in recent years have been in the field of deep learning. Natural language translation, image recognition, and game playing are all tasks where deep learning models have neared or even exceeded human-level performance.\n",
    "\n",
    "So what is deep learning? Deep learning is an approach to machine learning characterized by deep stacks of computations. This depth of computation is what has enabled deep learning models to disentangle the kinds of complex and hierarchical patterns found in the most challenging real-world datasets.\n",
    "\n",
    "Through their power and scalability neural networks have become the defining model of deep learning. Neural networks are composed of neurons, where each neuron individually performs only a simple computation. The power of a neural network comes instead from the complexity of the connections these neurons can form.\n",
    "\n",
    "# The Linear Unit\n",
    "\n",
    "So let's begin with the fundamental component of a neural network: the individual neuron. As a diagram, a neuron (or unit) with one input looks like:\n",
    "\n",
    "## Diagram of a linear unit.\n",
    "\n",
    "The Linear Unit: 洧녽 = 洧녻洧논 + 洧녪\n",
    "\n",
    "<img src=\"https://i.imgur.com/mfOlDR6.png\" width=\"300\">\n",
    "\n",
    "The input is x. Its connection to the neuron has a weight which is w. Whenever a value flows through a connection, you multiply the value by the connection's weight. For the input x, what reaches the neuron is w * x. A neural network \"learns\" by modifying its weights.\n",
    "\n",
    "The b is a special kind of weight we call the bias. The bias doesn't have any input data associated with it; instead, we put a 1 in the diagram so that the value that reaches the neuron is just b (since 1 * b = b). The bias enables the neuron to modify the output independently of its inputs.\n",
    "\n",
    "The y is the value the neuron ultimately outputs. To get the output, the neuron sums up all the values it receives through its connections. This neuron's activation is <code>y = w * x + b</code>, or as a formula 洧녽 = 洧녻洧논 + 洧녪.\n",
    "\n",
    "Does the formula 洧녽 = 洧녻洧논 + 洧녪 look familiar?\n",
    "It's an equation of a line! It's the slope-intercept equation, where 洧녻 is the slope and 洧녪 is the y-intercept.\n",
    "\n",
    "## Example - The Linear Unit as a Model\n",
    "\n",
    "Though individual neurons will usually only function as part of a larger network, it's often useful to start with a single neuron model as a baseline. Single neuron models are linear models.\n",
    "\n",
    "Let's think about how this might work on a dataset like 80 Cereals. Training a model with 'sugars' (grams of sugars per serving) as input and 'calories' (calories per serving) as output, we might find the bias is b=90 and the weight is w=2.5. We could estimate the calorie content of a cereal with 5 grams of sugar per serving like this:\n",
    "\n",
    "<img src=\"https://i.imgur.com/yjsfFvY.png\" width=\"500\">\n",
    "\n",
    "And, checking against our formula, we have 洧녫洧녩洧녳洧녶洧洧녰洧뉧롐=2.5칑5+90=102.5, just like we expect.\n",
    "\n",
    "## Multiple Inputs\n",
    "The 80 Cereals dataset has many more features than just 'sugars'. What if we wanted to expand our model to include things like fiber or protein content? That's easy enough. We can just add more input connections to the neuron, one for each additional feature. To find the output, we would multiply each input to its connection weight and then add them all together.\n",
    "\n",
    "Three input connections: x0, x1, and x2, along with the bias.\n",
    "\n",
    "<img src=\"https://i.imgur.com/vyXSnlZ.png\" width=\"300\">\n",
    "\n",
    "The formula for this neuron would be 洧녽=洧녻0洧논0+洧녻1洧논1+洧녻2洧논2+洧녪. A linear unit with two inputs will fit a plane, and a unit with more inputs than that will fit a hyperplane.\n",
    "\n",
    "## Linear Units in Keras\n",
    "The easiest way to create a model in Keras is through keras.Sequential, which creates a neural network as a stack of layers. We can create models like those above using a dense layer (which we'll learn more about in the next lesson).\n",
    "\n",
    "We could define a linear model accepting three input features ('sugars', 'fiber', and 'protein') and producing a single output ('calories')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 21:11:14.047760: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# create a network with 1 linear unit\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=1, input_shape=[3])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49102747a477ec872ce5c57af32e04f52205abcec8f436ba78cc541d2e49f433"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('mlearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
